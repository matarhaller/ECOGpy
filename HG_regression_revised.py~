from __future__ import division
import os
import numpy as np
import cPickle as pickle
import sys
import pandas as pd
from sklearn import cross_validation, grid_search
from sklearn.linear_model import Ridge
from sklearn.preprocessing import scale
from collections import Counter
from scipy import stats
import matplotlib.pyplot as plt

def HG_regression_allelecs_SGE(DATASET):
    """
    feeds in subj/task to HG_regression_all_elecs and saves output to file
    """
    SJdir = '/home/knight/matar/MATLAB/DATA/Avgusta'
    subj, task = DATASET.split('_')
    
    data_dict = HG_regression_allelecs(subj, task)

    filename = os.path.join(SJdir, 'PCA', 'Stats', 'Regression', '_'.join([subj, task]))

    pickle.dump(data_dict, open(filename + '.p', 'wb'))
    
    ##STOPPED HERE - need to convert variables in data dict to fit the array
    elec, alphas, scores, zcoefs, pval  = [data_dict[key] for key in ['elec','alphas','scores', 'zcoefs', 'pval']]
    score = np.median(scores, axis = 0)
    alpha = np.median(alphas, axis = 0)

    data_array = np.hstack((np.asarray(zcoefs), np.reshape(score, (len(score), 1)), np.reshape(pval, (len(pvals), 1)), np.reshape(alpha, (len(alpha), 1))))

    #    data_array =  np.hstack((np.asarray(betas), np.reshape(predscores, (len(predscores), 1)), np.reshape(pvals, (len(pvals), 1)), np.reshape(all_alphas, (len(all_alphas), 1))))
    features.append('pred_score')
    features.append('pval_predscore')
    features.append('alpha')

    df = pd.DataFrame(data_array, columns = features, index = elecs)
    df.to_csv(filename + '_coefs.csv')
    

def HG_regression_allelecs(subj, task): 
    '''
    Runs ridge regression on maxes, means, stds, sums, latency (proportion) data for a subj/task
    Loops on each electrode
    Splits data into training and test sets
    Runs 10 fold CV to get best alpha on training set
    Gets best model, best coefficients, best score
    Calculates a null prediction score by predicting shuffled test set
    Outputs dictionary of lists of coefficients, prediction scores, models, null prediction scores for each duration electrode
    '''
    SJdir = '/home/knight/matar/MATLAB/DATA/Avgusta'

    # load data
    filename = os.path.join(SJdir, 'PCA', 'ShadePlots_hclust', 'elecs', 'significance_windows', 'data', ''.join([subj, '_', task, '.p']))
    data_dict = pickle.load(open(filename, 'rb'))
   
    all_alphas, betas, predscores, pvals = [[] for i in range(4)]

    #set parameters
    #features = ['maxes', 'means', 'stds', 'sums', 'lats_pro']
    features = ['maxes', 'means', 'stds', 'lats_pro']
    predictor = 'RTs'

    elecs = data_dict['means'].keys()

    for elec in elecs:

        #define data
        X = np.array([data_dict[x][elec] for x in features]).T
        Y = data_dict[predictor][elec]

        #drop nans from data
        mask = np.all(np.isnan(X), axis = 1)
        X = X[~mask]
        mask = np.isnan(Y)
        Y = Y[~mask]        

        #split data into training and test sets for the number of CV folds
        cvs = cross_validation.ShuffleSplit(len(Y), n_iter = 1000, test_size = 0.2)

        alphas, models, scores, coefs, scores_null = [[] for i in range(5)]
        
        for train, test in cvs:
            #scale training and test data
            X_train = scale(X[train].astype(float))
            X_test = scale(X[test].astype(float))
            y_train = scale(Y[train].astype(float))
            y_test = scale(Y[test].astype(float))

            #define model (search over 10 alphas)
            model = Ridge(solver = 'lsqr', normalize=False, fit_intercept=False)
            params_grid = {'alpha': np.logspace(-4, 4, 10)}
            ridge_grid = grid_search.GridSearchCV(model, params_grid, cv = 10)

            #fit and find best model
            ridge_grid.fit(X_train, y_train)
            mod = ridge_grid.best_estimator_
            score = np.corrcoef(mod.predict(X_test), y_test)[1,0]
            coef = mod.coef_
            a = mod.alpha

            #calculate permuted score
            idx = np.random.permutation(len(y_test))
            null_score = np.corrcoef(mod.predict(X_test), y_test[idx])[1,0] #predict on shuffled test set

            #add to list
            alphas.append(a)
            models.append(mod)
            scores.append(score)
            coefs.append(coef)
            scores_null.append(null_score)
        
        if np.median(scores)>0:
            pval = 1 - (sum(np.median(scores) > scores_null)/ len(scores_null))
        elif np.median(scores)<0:
            pval = 1 - (sum(np.median(scores) < scores_null) / len(scores_null))
        else:
            pval = 1


        #zscore coefficients, take mean
        zcoefs = stats.zscore(coefs, axis = 0)
        zcoefs = np.mean(coefs, axis = 0)


        data_dict['elec'] = elec
        data_dict['alphas'] = alphas
        data_dict['models'] = models
        data_dict['scores'] = scores
        data_dict['coefs'] = coefs
        data_dict['scores_null'] = scores_null
        data_dict['pval'] = pval
        data_dict['zcoefs'] = zcoefs

        #### FIGURES ####
        #plot alpha distribution
        count_dict = Counter(alphas)
        i = np.argsort(count_dict.keys())
        sorted_values = np.array(count_dict.values())[i]
        sorted_keys = np.array(count_dict.keys())[i]
        
        f, ax = plt.subplots()
        ax.plot(sorted_values)
        ax.set_xticks(range(len(sorted_keys)))
        ax.set_xticklabels(['%.f' %x for x in sorted_keys])
        ax.set_title('distribution of alphas')
        
        plotname = os.path.join(SJdir, 'PCA','Stats','Regression', '_'.join([subj, task, str(elec), 'alpha_distribution.png']))
        plt.savefig(plotname)

        #plot histogram of scores vs null distribution
        f, ax = plt.subplots()
        ax.hist(scores)
        ax.hist(scores_null, color = 'r', alpha = 0.5)
        ax.set_title('distribution of scores, p =  %.2f' %pval)
        
        plotname = os.path.join(SJdir, 'PCA','Stats','Regression', '_'.join([subj, task, str(elec), 'score_distribution.png']))
        plt.savefig(plotname)

        #plot histogram of coefficients
        f,ax = plt.subplots(2,2, figsize = (10,7))
        for i, x in enumerate(features):
            idx = np.unravel_index(i, (2,2))
            ax[idx].hist(np.array(coefs)[:,i])
            ax[idx].set_title(x)
        f.suptitle('betas')

        plotname = os.path.join(SJdir, 'PCA', 'Stats', 'Regression', '_'.join([subj, task, str(elec), 'coefficients.png']))
        plt.savefig(plotname)

    return data_dict


if __name__ == '__main__':
    DATASET = sys.argv[1]
    HG_regression_allelecs_SGE(DATASET)
