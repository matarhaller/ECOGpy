{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import loadmat\n",
    "%pylab inline\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SJdir = '/home/knight/matar/MATLAB/DATA/Avgusta/'\n",
    "subj, task = ('GP15','EmoGen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>t2 (last cross)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>426</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>475</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RT  t2 (last cross)\n",
       "0  325              212\n",
       "1  382              228\n",
       "2  426              341\n",
       "3  475              389\n",
       "4  524              406"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(SJdir, 'PCA', 'csvs_FINAL','Bin_Stats_v1_D+R.csv')\n",
    "df_val = pd.read_csv(filename)\n",
    "df_val[['RT','t2 (last cross)']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SJdir = '/home/knight/matar/MATLAB/DATA/Avgusta/'\n",
    "filename = os.path.join(SJdir, 'PCA', 'csvs_FINAL', 'mean_traces_all_subjs_dropSR.csv')\n",
    "df = pd.read_csv(filename)\n",
    "df = df[(df.subj == subj) & (df.task == task)]\n",
    "elecs = df[(df.pattern == 'D') | (df.pattern == 'R')].elec.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLV - phase phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'lf_hg_phase')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "lf_phase, srate = [data_dict.get(key) for key in ['lf_phase', 'srate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if subj in ['GP15', 'GP35']:\n",
    "    filename = os.path.join(SJdir, 'Subjs', subj, task, 'subj_globals.mat')\n",
    "    data_dict = loadmat.loadmat(filename)\n",
    "    original_srate = data_dict['srate'] #1017.3\n",
    "else:\n",
    "    original_srate = srate #JH2 is 1000 for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 'D'\n",
    "filename= os.path.join(SJdir, 'SingleTrials','alltrials','data', 'singletrials_allelecs_smooth_nodecision_' + p + '_dropSR.mat')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "allRTs = data_dict['allRTs']\n",
    "\n",
    "bins = np.arange(allRTs.min(), allRTs.max(), 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add bin start and stop to df_vals\n",
    "starts, stops = [[] for i in range(2)]\n",
    "for i in range(df_val.shape[0]):\n",
    "    tmp = bins - df_val.iloc[i].RT\n",
    "    idx = np.where(tmp<0)[0][-1]\n",
    "    start, stop = bins[idx:idx+2]\n",
    "    starts.append(start)\n",
    "    stops.append(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>t2 (last cross)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2229</td>\n",
       "      <td>2200</td>\n",
       "      <td>2250</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2275</td>\n",
       "      <td>2250</td>\n",
       "      <td>2300</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2328</td>\n",
       "      <td>2300</td>\n",
       "      <td>2350</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2525</td>\n",
       "      <td>2500</td>\n",
       "      <td>2550</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3126</td>\n",
       "      <td>3100</td>\n",
       "      <td>3150</td>\n",
       "      <td>2981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RT  start  stop  t2 (last cross)\n",
       "38  2229   2200  2250             2105\n",
       "39  2275   2250  2300             2042\n",
       "40  2328   2300  2350             2132\n",
       "41  2525   2500  2550             2105\n",
       "42  3126   3100  3150             2981"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['start'] = starts\n",
    "df_val['stop'] = stops\n",
    "\n",
    "df_val[['RT','start','stop','t2 (last cross)']].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF PLV across time - 1 value per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in onsets, offsets\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_word_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_stim = data_dict['onsets_word_corr_g']/original_srate*1000\n",
    "\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_resp_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_resp = data_dict['onsets_resp_corr_g']/original_srate*1000\n",
    "\n",
    "#calculate RT, drop outliers\n",
    "RTs = onsets_resp - onsets_stim\n",
    "goodidx = (RTs > mean(RTs) - 3* std(RTs)) * (RTs < mean(RTs) + 3 * std(RTs))\n",
    "RTs = RTs[goodidx]\n",
    "onsets_stim = onsets_stim[goodidx]\n",
    "onsets_resp = onsets_resp[goodidx]\n",
    "\n",
    "#for each trial, calculate which RT bin it falls in, calculate crossover point (make array of crossoverpoints)\n",
    "bin_idx = np.digitize(RTs, starts)-1\n",
    "crossovers = df_val.iloc[bin_idx]['t2 (last cross)']\n",
    "\n",
    "#take relevant window across crossover point - build matrix\n",
    "lf_c_dict,lf_baseline_dict, lf_pre_c_dict, lf_post_c_dict, = [dict() for i in range(4)]\n",
    "for e in elecs:    \n",
    "    lf_c_trials, lf_pre_c_trials, lf_post_c_trials, lf_baseline_trials = [np.empty((len(onsets_stim),250)) for i in range(4)]\n",
    "    \n",
    "    for i, c in enumerate(crossovers.values):\n",
    "        c_point = int((onsets_stim[i]+c))\n",
    "        lf_c_trials[i,:] = lf_phase[e, c_point - 125 : c_point + 125]\n",
    "        lf_pre_c_trials[i,:] = lf_phase[e, c_point - 250 : c_point]\n",
    "        lf_post_c_trials[i,:] = lf_phase[e, c_point : c_point + 250]\n",
    "        lf_baseline_trials[i,:] = lf_phase[e, onsets_stim[i] - 250 : onsets_stim[i]]\n",
    "        \n",
    "    lf_c_dict[e] = lf_c_trials    \n",
    "    lf_pre_c_dict[e] = lf_pre_c_trials\n",
    "    lf_post_c_dict[e] = lf_post_c_trials\n",
    "    lf_baseline_dict[e] = lf_baseline_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate pac - one value per trial (mean across time)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "for e1 in elecs:\n",
    "    for e2 in elecs:\n",
    "        if e1<=e2:\n",
    "            pattern = '%s-%s' %(df[df.elec == e1].pattern.values[0], df[df.elec == e2].pattern.values[0])\n",
    "\n",
    "            f, ax = plt.subplots(2, 2, subplot_kw=dict(projection='polar'), figsize = (10,10))\n",
    "            plt.suptitle('%s %s PLV : e%i (LF) - e%i (HG) : %s' %(subj, task, e1, e2, pattern))\n",
    "            ax = ax.flatten()\n",
    "\n",
    "            plv_c, plv_pre_c, plv_post_c, plv_baseline = [[] for i in range(4)]\n",
    "            for i in range(len(onsets_stim)): #per trial\n",
    "                plv_c.append(lf_c_dict[e1][i,:] - lf_c_dict[e2][i,:])\n",
    "                plv_pre_c.append(lf_pre_c_dict[e1][i,:] - lf_pre_c_dict[e2][i,:])\n",
    "                plv_post_c.append(lf_post_c_dict[e1][i,:] - lf_post_c_dict[e2][i,:])\n",
    "                plv_baseline.append(lf_baseline_dict[e1][i,:] - lf_baseline_dict[e2][i,:])\n",
    "\n",
    "            plv_c = np.mean(exp(1j * np.array(plv_c)), 1) #1 complex value per trial\n",
    "            plv_pre_c = np.mean(exp(1j * np.array(plv_pre_c)), 1)\n",
    "            plv_post_c = np.mean(exp(1j * np.array(plv_post_c)), 1)\n",
    "            plv_baseline = np.mean(exp(1j * np.array(plv_baseline)), 1)\n",
    "\n",
    "            for i in plv_baseline:\n",
    "                ax[0].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "            ax[0].plot([0, mean(angle(plv_baseline))], [0, mean(abs(plv_baseline))], color = 'k', lw = 4)\n",
    "            ax[0].set_title(\"baseline = %.2f\" %(mean(abs(plv_baseline))))\n",
    "\n",
    "            for i in plv_pre_c:\n",
    "                ax[1].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "            ax[1].plot([0, (mean(angle(plv_pre_c)))], [0, mean(abs(plv_pre_c))], color = 'k', lw = 4)\n",
    "            ax[1].set_title(\"pre cross = %.2f\" %(mean(abs(plv_pre_c))))\n",
    "\n",
    "            for i in plv_c: #per trial\n",
    "                ax[2].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "            ax[2].plot([0, (mean(angle(plv_c)))], [0, mean(abs(plv_c))], color = 'k', lw = 4)\n",
    "            ax[2].set_title(\"crossover = %.2f\" %(mean(abs(plv_c))))\n",
    "\n",
    "            for i in plv_post_c:\n",
    "                ax[3].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "            ax[3].plot([0, mean(angle(plv_post_c))], [0, mean(abs(plv_post_c))], color = 'k', lw = 4)\n",
    "            ax[3].set_title(\"post cross = %.2f\" %(mean(abs(plv_post_c))))\n",
    "\n",
    "            filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/LF_PLV/figures/%s_%s_e%i_e%i_trials.png' %(subj, task, e1, e2)\n",
    "            f.savefig(filename, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            tmp = tmp.append({'LF_elec1': e1, 'LF_elec2' : e2, 'window': 'baseline', 'plv' : mean(abs(plv_baseline)), 'p': 1}, ignore_index = True)\n",
    "\n",
    "            _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_pre_c)))\n",
    "            tmp = tmp.append({'LF_elec1': e1, 'LF_elec2' : e2, 'window': 'pre', 'plv' : mean(abs(plv_pre_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "            _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_c)))\n",
    "            tmp = tmp.append({'LF_elec1': e1, 'LF_elec2' : e2, 'window': 'cross', 'plv' : mean(abs(plv_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "            _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_post_c)))\n",
    "            tmp = tmp.append({'LF_elec1': e1, 'LF_elec2' : e2, 'window': 'post', 'plv' : mean(abs(plv_post_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/LF_PLV/%s_%s_plv_trials.csv' %(subj, task)\n",
    "tmp.to_csv(filename, index = False)\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLV across trials - 1 value per time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in onsets, offsets\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_word_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_stim = data_dict['onsets_word_corr_g']/original_srate*1000\n",
    "\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_resp_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_resp = data_dict['onsets_resp_corr_g']/original_srate*1000\n",
    "\n",
    "#calculate RT, drop outliers\n",
    "RTs = onsets_resp - onsets_stim\n",
    "goodidx = (RTs > mean(RTs) - 3* std(RTs)) * (RTs < mean(RTs) + 3 * std(RTs))\n",
    "RTs = RTs[goodidx]\n",
    "onsets_stim = onsets_stim[goodidx]\n",
    "onsets_resp = onsets_resp[goodidx]\n",
    "\n",
    "#for each trial, calculate which RT bin it falls in, calculate crossover point (make array of crossoverpoints)\n",
    "bin_idx = np.digitize(RTs, starts)-1\n",
    "crossovers = df_val.iloc[bin_idx]['t2 (last cross)']\n",
    "\n",
    "#take relevant window across crossover point - build matrix\n",
    "lf_c_dict,lf_baseline_dict,lf_pre_c_dict, lf_post_c_dict = [dict() for i in range(4)]\n",
    "for e in elecs:    \n",
    "    lf_c_trials, hg_c_trials = [np.empty((len(onsets_stim),1000)) for i in range(2)]\n",
    "    \n",
    "    for i, c in enumerate(crossovers.values):\n",
    "        c_point = int((onsets_stim[i]+c))\n",
    "        lf_c_trials[i,:] = lf_phase[e, c_point - 500 : c_point + 500]        \n",
    "    lf_c_dict[e] = lf_c_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate plv - one value per timepoint (mean across trials, 1000 points)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "for e1 in elecs:\n",
    "    for e2 in elecs:\n",
    "        if e1<e2:\n",
    "            pattern = '%s-%s' %(df[df.elec == e1].pattern.values[0], df[df.elec == e2].pattern.values[0])\n",
    "\n",
    "            phase_diff = list()\n",
    "            for i in range(len(onsets_stim)): #per trial\n",
    "                phase_diff.append(lf_c_dict[e1][i,:] - lf_c_dict[e2][i,:])\n",
    "\n",
    "            plv_c = np.mean(exp(1j * np.array(phase_diff)), 0) #average across trials, get time series\n",
    "\n",
    "            plv_c_z = (abs(plv_c) - np.mean(abs(plv_c))) / np.std(abs(plv_c))\n",
    "\n",
    "            #tmp = tmp.append(pd.DataFrame({'LF_elec': [e1] *1000, 'HG_elec' : [e2] * 1000, 'pattern': [pattern] * 1000, 'plv' : pd.Series(abs(plv_c), name = 'plv', index = np.arange(-500,500))}))\n",
    "            tmp = tmp.append(pd.DataFrame({'LF_elec1': [e1] *1000, 'LF_elec2' : [e2] * 1000, 'pattern': [pattern] * 1000, 'plv' : pd.Series(plv_c_z, name = 'plv', index = np.arange(-500,500))}))\n",
    "            f, ax = plt.subplots()\n",
    "            ax.plot(range(-500, 500), abs(plv_c))\n",
    "            ax.set_xlim([-500, 500])\n",
    "            ax.set_ylim([-0.1, 1])\n",
    "\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.get_xaxis().tick_bottom()\n",
    "            ax.get_yaxis().tick_left()\n",
    "            ax.tick_params( axis='both', which = 'both', top = 'off', bottom = 'off', right = 'off', left = 'off')\n",
    "\n",
    "            ax.axvline(0, color = 'k')\n",
    "            ax.axhline(0, color = 'k')\n",
    "\n",
    "            filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/LF_PLV/figures/time/%s_%s_e%i_e%i_time.png' %(subj, task, e1, e2)\n",
    "            f.savefig(filename, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "df_zscore = tmp.reset_index()\n",
    "df_zscore.columns = ['time','LF_elec1','LF_elec2','pattern','plv'] #zscored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'lf_hg_phase')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "hg_phase, lf_phase, srate = [data_dict.get(key) for key in ['hg_phase','lf_phase', 'srate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(SJdir, 'Subjs', subj ,task, 'gdat_notch')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "gdat = data_dict['gdat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if subj in ['GP15', 'GP35']:\n",
    "    filename = os.path.join(SJdir, 'Subjs', subj, task, 'subj_globals.mat')\n",
    "    data_dict = loadmat.loadmat(filename)\n",
    "    original_srate = data_dict['srate'] #1017.3\n",
    "else:\n",
    "    original_srate = srate #JH2 is 1000 for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1, f2 = (7,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slow phase time series\n",
    "phs_bp = mne.filter.band_pass_filter(gdat, srate, f1, f2)\n",
    "phs_ang = np.angle(hilbert(phs_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fast phase time series\n",
    "amp_bp = mne.filter.band_pass_filter(gdat, srate, 70, 150)\n",
    "amp_env = np.absolute(hilbert(amp_bp))\n",
    "amp_env_bp = mne.filter.band_pass_filter(amp_env, srate, f1, f2)\n",
    "amp_env_ang = np.angle(hilbert(amp_env_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(SJdir, 'PCA', 'csvs_FINAL','Bin_Stats_v1_D+R.csv')\n",
    "df_val = pd.read_csv(filename)\n",
    "df_val[['RT','t2 (last cross)']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SJdir = '/home/knight/matar/MATLAB/DATA/Avgusta/'\n",
    "filename = os.path.join(SJdir, 'PCA', 'csvs_FINAL', 'mean_traces_all_subjs_dropSR.csv')\n",
    "df = pd.read_csv(filename)\n",
    "df = df[(df.subj == subj) & (df.task == task)]\n",
    "elecs = df[(df.pattern == 'D') | (df.pattern == 'R')].elec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 'D'\n",
    "filename= os.path.join(SJdir, 'SingleTrials','alltrials','data', 'singletrials_allelecs_smooth_nodecision_' + p + '_dropSR.mat')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "allRTs = data_dict['allRTs']\n",
    "\n",
    "bins = np.arange(allRTs.min(), allRTs.max(), 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add bin start and stop to df_vals\n",
    "starts, stops = [[] for i in range(2)]\n",
    "for i in range(df_val.shape[0]):\n",
    "    tmp = bins - df_val.iloc[i].RT\n",
    "    idx = np.where(tmp<0)[0][-1]\n",
    "    start, stop = bins[idx:idx+2]\n",
    "    starts.append(start)\n",
    "    stops.append(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_val['start'] = starts\n",
    "df_val['stop'] = stops\n",
    "\n",
    "df_val[['RT','start','stop','t2 (last cross)']].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAC across time - plot 1 value per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in onsets, offsets\n",
    "\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_word_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_stim = data_dict['onsets_word_corr_g']/original_srate*1000\n",
    "\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_resp_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_resp = data_dict['onsets_resp_corr_g']/original_srate*1000\n",
    "\n",
    "#calculate RT, drop outliers\n",
    "RTs = onsets_resp - onsets_stim\n",
    "goodidx = (RTs > mean(RTs) - 3* std(RTs)) * (RTs < mean(RTs) + 3 * std(RTs))\n",
    "RTs = RTs[goodidx]\n",
    "onsets_stim = onsets_stim[goodidx]\n",
    "onsets_resp = onsets_resp[goodidx]\n",
    "\n",
    "#for each trial, calculate which RT bin it falls in, calculate crossover point (make array of crossoverpoints)\n",
    "bin_idx = np.digitize(RTs, starts)-1\n",
    "crossovers = df_val.iloc[bin_idx]['t2 (last cross)']\n",
    "\n",
    "#take relevant window across crossover point - build matrix\n",
    "lf_c_dict, hg_c_dict, lf_baseline_dict, hg_baseline_dict, lf_pre_c_dict, lf_post_c_dict, hg_pre_c_dict, hg_post_c_dict = [dict() for i in range(8)]\n",
    "for e in elecs:    \n",
    "    lf_c_trials, hg_c_trials, lf_pre_c_trials, hg_pre_c_trials, lf_post_c_trials, hg_post_c_trials, lf_baseline_trials, hg_baseline_trials = [np.empty((len(onsets_stim),250)) for i in range(8)]\n",
    "    \n",
    "    for i, c in enumerate(crossovers.values):\n",
    "        c_point = int((onsets_stim[i]+c))\n",
    "        lf_c_trials[i,:] = lf_phase[e, c_point - 125 : c_point + 125]\n",
    "        hg_c_trials[i,:] = hg_phase[e, c_point-125 : c_point + 125]\n",
    "        \n",
    "        lf_pre_c_trials[i,:] = lf_phase[e, c_point - 250 : c_point]\n",
    "        hg_pre_c_trials[i,:] = hg_phase[e, c_point - 250 : c_point]\n",
    "        \n",
    "        lf_post_c_trials[i,:] = lf_phase[e, c_point : c_point + 250]\n",
    "        hg_post_c_trials[i,:] = hg_phase[e, c_point : c_point + 250]\n",
    "        \n",
    "        lf_baseline_trials[i,:] = lf_phase[e, onsets_stim[i] - 250 : onsets_stim[i]]\n",
    "        hg_baseline_trials[i,:] = hg_phase[e, onsets_stim[i] - 250 : onsets_stim[i]]\n",
    "        \n",
    "    lf_c_dict[e] = lf_c_trials\n",
    "    hg_c_dict[e] = hg_c_trials\n",
    "    \n",
    "    lf_pre_c_dict[e] = lf_pre_c_trials\n",
    "    hg_pre_c_dict[e] = hg_pre_c_trials\n",
    "    \n",
    "    lf_post_c_dict[e] = lf_post_c_trials\n",
    "    hg_post_c_dict[e] = hg_post_c_trials\n",
    "    \n",
    "    lf_baseline_dict[e] = lf_baseline_trials\n",
    "    hg_baseline_dict[e] = hg_baseline_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate pac - one value per trial (mean across time)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "for e1 in elecs:\n",
    "    for e2 in elecs:\n",
    "        pattern = '%s-%s' %(df[df.elec == e1].pattern.values[0], df[df.elec == e2].pattern.values[0])\n",
    "        \n",
    "        f, ax = plt.subplots(2, 2, subplot_kw=dict(projection='polar'), figsize = (10,10))\n",
    "        plt.suptitle('%s %s PLV : e%i (LF) - e%i (HG) : %s' %(subj, task, e1, e2, pattern))\n",
    "        ax = ax.flatten()\n",
    "\n",
    "        plv_c, plv_pre_c, plv_post_c, plv_baseline = [[] for i in range(4)]\n",
    "        for i in range(len(onsets_stim)): #per trial\n",
    "            plv_c.append(lf_c_dict[e1][i,:] - hg_c_dict[e2][i,:])\n",
    "            plv_pre_c.append(lf_pre_c_dict[e1][i,:] - hg_pre_c_dict[e2][i,:])\n",
    "            plv_post_c.append(lf_post_c_dict[e1][i,:] - hg_post_c_dict[e2][i,:])\n",
    "            plv_baseline.append(lf_baseline_dict[e1][i,:] - hg_baseline_dict[e2][i,:])\n",
    "            \n",
    "        plv_c = np.mean(exp(1j * np.array(plv_c)), 1) #1 complex value per trial\n",
    "        plv_pre_c = np.mean(exp(1j * np.array(plv_pre_c)), 1)\n",
    "        plv_post_c = np.mean(exp(1j * np.array(plv_post_c)), 1)\n",
    "        plv_baseline = np.mean(exp(1j * np.array(plv_baseline)), 1)\n",
    "        \n",
    "        for i in plv_baseline:\n",
    "            ax[0].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "        ax[0].plot([0, mean(angle(plv_baseline))], [0, mean(abs(plv_baseline))], color = 'k', lw = 4)\n",
    "        ax[0].set_title(\"baseline = %.2f\" %(mean(abs(plv_baseline))))\n",
    "\n",
    "        for i in plv_pre_c:\n",
    "            ax[1].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "        ax[1].plot([0, (mean(angle(plv_pre_c)))], [0, mean(abs(plv_pre_c))], color = 'k', lw = 4)\n",
    "        ax[1].set_title(\"pre cross = %.2f\" %(mean(abs(plv_pre_c))))\n",
    "\n",
    "        for i in plv_c: #per trial\n",
    "            ax[2].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "        ax[2].plot([0, (mean(angle(plv_c)))], [0, mean(abs(plv_c))], color = 'k', lw = 4)\n",
    "        ax[2].set_title(\"crossover = %.2f\" %(mean(abs(plv_c))))\n",
    "        \n",
    "        for i in plv_post_c:\n",
    "            ax[3].plot([0, i.real], [0, i.imag], color = 'b', alpha = 0.5)\n",
    "        ax[3].plot([0, mean(angle(plv_post_c))], [0, mean(abs(plv_post_c))], color = 'k', lw = 4)\n",
    "        ax[3].set_title(\"post cross = %.2f\" %(mean(abs(plv_post_c))))\n",
    "        \n",
    "        filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/figures/%s_%s_e%i_e%i_trials.png' %(subj, task, e1, e2)\n",
    "        f.savefig(filename, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        tmp = tmp.append({'LF_elec': e1, 'HG_elec' : e2, 'window': 'baseline', 'plv' : mean(abs(plv_baseline)), 'p': 1}, ignore_index = True)\n",
    "\n",
    "        _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_pre_c)))\n",
    "        tmp = tmp.append({'LF_elec': e1, 'HG_elec' : e2, 'window': 'pre', 'plv' : mean(abs(plv_pre_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "        _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_c)))\n",
    "        tmp = tmp.append({'LF_elec': e1, 'HG_elec' : e2, 'window': 'cross', 'plv' : mean(abs(plv_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "        _, pval = stats.ttest_ind(np.arctanh(abs(plv_baseline)), np.arctanh(abs(plv_post_c)))\n",
    "        tmp = tmp.append({'LF_elec': e1, 'HG_elec' : e2, 'window': 'post', 'plv' : mean(abs(plv_post_c)), 'p': pval}, ignore_index = True)\n",
    "\n",
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/%s_%s_plv_trials.csv' %(subj, task)\n",
    "#tmp.to_csv(filename, index = False)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# v = pd.DataFrame({'raw complex': plv_c, 'absolute' : abs(plv_c),  'fisher transform' : np.arctanh(abs(plv_c))})\n",
    "# v = v[['raw complex','absolute', 'fisher transform']]\n",
    "# v.to_csv('/home/knight/matar/JH2_e2_e3_PAC.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAC across trials - 1 value per time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in onsets, offsets\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_word_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_stim = data_dict['onsets_word_corr_g']/original_srate*1000\n",
    "\n",
    "filename= os.path.join(SJdir, 'Subjs', subj, task, 'onsets_resp_corr_g')\n",
    "data_dict = loadmat.loadmat(filename)\n",
    "onsets_resp = data_dict['onsets_resp_corr_g']/original_srate*1000\n",
    "\n",
    "#calculate RT, drop outliers\n",
    "RTs = onsets_resp - onsets_stim\n",
    "goodidx = (RTs > mean(RTs) - 3* std(RTs)) * (RTs < mean(RTs) + 3 * std(RTs))\n",
    "RTs = RTs[goodidx]\n",
    "onsets_stim = onsets_stim[goodidx]\n",
    "onsets_resp = onsets_resp[goodidx]\n",
    "\n",
    "#for each trial, calculate which RT bin it falls in, calculate crossover point (make array of crossoverpoints)\n",
    "bin_idx = np.digitize(RTs, starts)-1\n",
    "crossovers = df_val.iloc[bin_idx]['t2 (last cross)']\n",
    "\n",
    "#take relevant window across crossover point - build matrix\n",
    "lf_c_dict, hg_c_dict, lf_baseline_dict, hg_baseline_dict, lf_pre_c_dict, lf_post_c_dict, hg_pre_c_dict, hg_post_c_dict = [dict() for i in range(8)]\n",
    "for e in elecs:    \n",
    "    lf_c_trials, hg_c_trials = [np.empty((len(onsets_stim),1000)) for i in range(2)]\n",
    "    \n",
    "    for i, c in enumerate(crossovers.values):\n",
    "        c_point = int((onsets_stim[i]+c))\n",
    "        lf_c_trials[i,:] = lf_phase[e, c_point - 500 : c_point + 500]\n",
    "        hg_c_trials[i,:] = hg_phase[e, c_point - 500 : c_point + 500]\n",
    "        \n",
    "    lf_c_dict[e] = lf_c_trials\n",
    "    hg_c_dict[e] = hg_c_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate plv - one value per timepoint (mean across trials, 1000 points)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "for e1 in elecs:\n",
    "    for e2 in elecs:\n",
    "        pattern = '%s-%s' %(df[df.elec == e1].pattern.values[0], df[df.elec == e2].pattern.values[0])\n",
    "\n",
    "        phase_diff = list()\n",
    "        for i in range(len(onsets_stim)): #per trial\n",
    "            phase_diff.append(lf_c_dict[e1][i,:] - hg_c_dict[e2][i,:])\n",
    "            \n",
    "        plv_c = np.mean(exp(1j * np.array(phase_diff)), 0) #average across trials, get time series\n",
    "        \n",
    "        plv_c_z = (abs(plv_c) - np.mean(abs(plv_c))) / np.std(abs(plv_c))\n",
    "        \n",
    "        #tmp = tmp.append(pd.DataFrame({'LF_elec': [e1] *1000, 'HG_elec' : [e2] * 1000, 'pattern': [pattern] * 1000, 'plv' : pd.Series(abs(plv_c), name = 'plv', index = np.arange(-500,500))}))\n",
    "        tmp = tmp.append(pd.DataFrame({'LF_elec': [e1] *1000, 'HG_elec' : [e2] * 1000, 'pattern': [pattern] * 1000, 'plv' : pd.Series(plv_c_z, name = 'plv', index = np.arange(-500,500))}))\n",
    "#         f, ax = plt.subplots()\n",
    "#         ax.plot(range(-500, 500), abs(plv_c))\n",
    "#         ax.set_xlim([-500, 500])\n",
    "#         ax.set_ylim([-0.1, 1])\n",
    "\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.get_xaxis().tick_bottom()\n",
    "#         ax.get_yaxis().tick_left()\n",
    "#         ax.tick_params( axis='both', which = 'both', top = 'off', bottom = 'off', right = 'off', left = 'off')\n",
    "        \n",
    "#         ax.axvline(0, color = 'k')\n",
    "#         ax.axhline(0, color = 'k')\n",
    "        \n",
    "#         filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/figures/time/%s_%s_e%i_e%i_time.png' %(subj, task, e1, e2)\n",
    "#         f.savefig(filename, bbox_inches='tight')\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_zscore = tmp.reset_index()\n",
    "df_zscore.columns = ['time','HG_elec','LF_elec','pattern','plv'] #zscored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stats on 300 ms flanking crossover point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_pre = df_zscore[(df_zscore.time<=0) & (df_zscore.time>-300)]\n",
    "# df_post = df_zscore[(df_zscore.time<300) & (df_zscore.time>=0)]\n",
    "dftmp = pd.DataFrame()\n",
    "for e1 in elecs:\n",
    "    for e2 in elecs:\n",
    "        #pattern = '%s-%s' %(df_zscore[df_zscore.HG_elec == e1].pattern.values[0], df_zscore[df_zscore.LF_elec == e2].pattern.values[0])\n",
    "        #pattern = np.unique(df_pre.pattern)[0]\n",
    "        #pre = df_pre[(df_pre.HG_elec == e1) & (df_pre.LF_elec == e2)].plv\n",
    "        #post = df_post[(df_post.HG_elec == e1) & (df_post.LF_elec == e2)].plv\n",
    "        df_plv = df_zscore[(df_zscore.HG_elec == e1) & (df_zscore.LF_elec == e2)]\n",
    "        pattern = np.unique(df_plv.pattern)[0]\n",
    "        pre = df_plv[(df_plv.time<=0) & (df_plv.time>-300)].plv\n",
    "        post = df_plv[(df_plv.time<300) & (df_plv.time>=0)].plv\n",
    "        t, pval = stats.ttest_ind(pre, post)\n",
    "        dftmp = dftmp.append({'LF_elec': e1, 'HG_elec' : e2, 'pattern': pattern, 'mean_pre' : pre.mean(), 'mean_post': post.mean(), 'p' : pval, 't': t}, ignore_index = True)\n",
    "\n",
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/plv_signifiance_crossover_300ms_zscore_%s_%s.csv' %(subj, task)\n",
    "dftmp.to_csv(filename)   \n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftmp[dftmp.p<0.0001].groupby('pattern').count().p/dftmp.groupby('pattern').count().p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stats on mean traces\n",
    "- mean of pre/post window per pair\n",
    "- ttest of all the means per pattern\n",
    "- output mean, t, p for each pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftmp = pd.DataFrame()\n",
    "for pattern in ['D-D','D-R','R-R','R-D']:\n",
    "    pre, post = [[] for i in range(2)]\n",
    "    for e1 in elecs:\n",
    "        for e2 in elecs:\n",
    "            df_plv = df_zscore[(df_zscore.HG_elec == e1) & (df_zscore.LF_elec == e2) & (df_zscore.pattern == pattern)]\n",
    "            pre.append(df_plv[(df_plv.time<=0) & (df_plv.time>-300)].plv.mean())\n",
    "            post.append(df_plv[(df_plv.time<300) & (df_plv.time>=0)].plv.mean())\n",
    "    \n",
    "            pre = [x for x in pre if str(x) != 'nan']    \n",
    "            post = [x for x in post if str(x) != 'nan'] \n",
    "\n",
    "    t, pval = stats.ttest_ind(pre, post)\n",
    "    dftmp = dftmp.append({'pattern': pattern, 'mean_pre' : np.nanmean(pre), 'mean_post': np.nanmean(post), 'p' : pval, 't': t}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dftmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/plv_signifiance_crossover_300_time_mean_%s_%s.csv' %(subj, task)\n",
    "dftmp.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftmp[dftmp.p<0.0001].groupby('pattern').count().p/dftmp.groupby('pattern').count().p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df_zscore.groupby('pattern').count()/1000\n",
    "f, ax = plt.subplots()\n",
    "# ax = df_zscore[df_zscore.pattern == 'D-D'].groupby('time').plv.mean().plot(label = 'D-D, %i' %(counts.loc['D-D'].time))\n",
    "# df_zscore[df_zscore.pattern == 'D-R'].groupby('time').plv.mean().plot(label = 'D-R, %i' %(counts.loc['D-R'].time))\n",
    "# df_zscore[df_zscore.pattern == 'R-D'].groupby('time').plv.mean().plot(label = 'R-D, %i' %(counts.loc['R-D'].time))\n",
    "for x in [('D-D','b'),('D-R','r'),('R-D','g')]:\n",
    "    pattern, c = x\n",
    "    n = df_zscore[df_zscore.pattern == pattern].groupby('time').plv.count().iloc[0]\n",
    "    plv_mean = df_zscore[df_zscore.pattern == pattern].groupby('time').plv.mean()\n",
    "    plv_sem = df_zscore[df_zscore.pattern == pattern].groupby('time').plv.std()/n\n",
    "    ax.plot(range(-500,500), plv_mean, label = '%s %i' %(pattern, n), color = c)\n",
    "    ax.fill_between(range(-500,500), plv_mean+plv_sem, plv_mean-plv_sem, alpha = 0.5, edgecolor = 'None', facecolor = c, label = None)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "ax.set_title('%s %s' %(subj, task))\n",
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/%s_%s_plv_time_pattern_avg.png' %(subj, task)\n",
    "#plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "pattern = 'D-D'\n",
    "tmp_pattern = tmp[tmp.pattern == pattern]\n",
    "HG = np.unique(tmp_pattern['HG_elec'])\n",
    "LF = np.unique(tmp_pattern['LF_elec'])\n",
    "\n",
    "for e1 in HG:\n",
    "    for e2 in LF:\n",
    "        tmp_pattern[(tmp_pattern.HG_elec == e1) & (tmp_pattern.LF_elec == e2)].plv.plot(alpha = 0.5)\n",
    "ax.set_title('%s %s %s' %(subj, task, pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run on all subj/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import crossover_analysis as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_dict = {'GP15': ['FaceGen','SelfAud','SelfVis', 'EmoRep','EmoGen']}\n",
    "subj_dict['GP35'] = ['FaceEmo','FaceGen', 'EmoRep',]\n",
    "subj_dict['JH2'] = ['SelfAud','SelfVis']\n",
    "\n",
    "for subj in subj_dict.keys():\n",
    "    for task in subj_dict[subj]:\n",
    "        print(subj, task)\n",
    "        ca.crossover_by_trials(subj, task)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine csv\n",
    "df_full = pd.DataFrame()\n",
    "files = glob.glob(os.path.join(SJdir, 'PCA','PLV', 'mean_traces', '*.csv'))\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    df['subj'] = f.split('_')[-2]\n",
    "    df['task'] = f.split('_')[-1][:-4]\n",
    "    df_full = df_full.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full[['subj','task','pattern', 'mean_post','mean_pre','t','p']]\n",
    "\n",
    "filename = os.path.join(SJdir, 'PCA','PLV', 'mean_traces', 'all_subjects_plv_signifiance_crossover_300_time_mean.csv')\n",
    "df_full.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(SJdir, 'PCA','PLV', 'flanking_300ms', '*.csv'))\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfmean = df.groupby('pattern').mean()[['mean_post', 'mean_pre', 'p','t']]\n",
    "    dfstd= df.groupby('pattern').std()[['mean_post', 'mean_pre', 'p','t']]\n",
    "    dfstd.columns = [x+'_std' for x in dfstd.columns]\n",
    "    df = pd.concat([dfmean, dfstd], axis = 1)\n",
    "    filename = f.split('.')[0]+'_summary.csv'\n",
    "    df.to_csv(filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame()\n",
    "files = glob.glob(os.path.join(SJdir, 'PCA','PLV', 'flanking_300ms', '*_summary.csv'))\n",
    "files = [x for x in files if 'all' not in x]\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    subj, task = f.split('_')[-3:-1]\n",
    "    df['subj'] = subj\n",
    "    df['task'] = task\n",
    "    df_full = df_full.append(df)\n",
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/flanking_300ms/plv_signifiance_crossover_300ms_zscore_all_subjs_summary.csv'\n",
    "df_full.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/%s_%s_plv.csv' %('GP35', task)\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df[df.pvalue<0.01].groupby(['window', 'pattern']).count()['pvalue'] / df[df['window']!='baseline'].groupby(['window','pattern']).count()['pvalue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(gp35[gp35.pvalue<0.01], values = 'pvalue', index = 'window', columns = 'pattern', aggfunc='count') / pd.pivot_table(gp35, values = 'pvalue', index = 'window', columns = 'pattern', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/%s_%s_plv.csv' %('GP15', task)\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df[df.pvalue<0.01].groupby(['window', 'pattern']).count()['pvalue'] / df[df['window']!='baseline'].groupby(['window','pattern']).count()['pvalue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/home/knight/matar/MATLAB/DATA/Avgusta/PCA/PLV/%s_%s_plv.csv' %('JH2', task)\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df[df.pvalue<0.01].groupby(['window', 'pattern']).count()['pvalue'] / df[df['window']!='baseline'].groupby(['window','pattern']).count()['pvalue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.pvalue<0.01].groupby(['window', 'pattern']).count()['pvalue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (10,10))\n",
    "f = ax.imshow(log10(mtx), interpolation='nearest')\n",
    "plt.colorbar(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e1 in [5]:\n",
    "    for e2 in elecs:\n",
    "        f, ax = plt.subplots()\n",
    "        ax.hist(np.arctanh(plv[e1,e2]))\n",
    "        ax.hist(np.arctanh(plv_baseline[e1,e2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(RTs - crossovers.values).mean() #average offset between RT and crossover point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
